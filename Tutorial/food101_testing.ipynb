{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of food101 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Compose, Resize\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/food101/\"\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def msg(\n",
    "    message: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        message (str): a message of type string, which will be printed to the terminal\n",
    "            with some decoration.\n",
    "\n",
    "    Description:\n",
    "        This function takes a message and prints it nicely\n",
    "\n",
    "    Output:\n",
    "        This function has no output, it prints directly to the terminal\n",
    "    \"\"\"\n",
    "\n",
    "    # word_list makes sure that the output of msg is more readable\n",
    "    sentence_list = message.split(sep=\"\\n\")\n",
    "    # the max-function can apparently be utilised like this:\n",
    "    longest_sentence = max(sentence_list, key=len)\n",
    "\n",
    "    n = len(longest_sentence)\n",
    "    n2 = n // 2 - 1\n",
    "    print(\">\" * n2 + \"  \" + \"<\" * n2)\n",
    "    print(message)\n",
    "    print(\">\" * n2 + \"  \" + \"<\" * n2 + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>>>>>>  <<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Split train data into trainset and validation set.\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>  <<<<<<<<<<<<<<<<<<<<<<<<\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainval_set = datasets.Food101(\n",
    "    root = DATA_PATH,\n",
    "    split = \"train\",                         \n",
    "    transform = Compose([ToTensor(), Resize([512, 512])]), \n",
    "    download = True\n",
    "    )\n",
    "\n",
    "test_set = datasets.Food101(\n",
    "    root = DATA_PATH, \n",
    "    split = \"test\", \n",
    "    transform =  Compose([ToTensor(), Resize([512, 512])]),\n",
    "    download = True\n",
    "    )\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "train_num = int(len(trainval_set) * (1 - VALIDATION_SPLIT))\n",
    "train_set, val_set = random_split(trainval_set, [train_num, len(trainval_set) - train_num])\n",
    "msg(\"Split train data into trainset and validation set.\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterable check\n",
    "It looks like a normal data set, when I pick them out as Tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[0.9412, 0.9490, 0.9569,  ..., 0.8314, 0.8039, 0.7882],\n",
      "         [0.9412, 0.9490, 0.9569,  ..., 0.8471, 0.8275, 0.8118],\n",
      "         [0.9451, 0.9490, 0.9529,  ..., 0.8431, 0.8235, 0.8078],\n",
      "         ...,\n",
      "         [0.8000, 0.8118, 0.8235,  ..., 0.6039, 0.5922, 0.5843],\n",
      "         [0.8000, 0.8157, 0.8275,  ..., 0.5725, 0.5686, 0.5647],\n",
      "         [0.8039, 0.8196, 0.8314,  ..., 0.5647, 0.5725, 0.5804]],\n",
      "\n",
      "        [[0.9451, 0.9529, 0.9608,  ..., 0.8824, 0.8549, 0.8392],\n",
      "         [0.9451, 0.9529, 0.9608,  ..., 0.8980, 0.8784, 0.8627],\n",
      "         [0.9490, 0.9529, 0.9569,  ..., 0.8941, 0.8745, 0.8588],\n",
      "         ...,\n",
      "         [0.8588, 0.8706, 0.8745,  ..., 0.6078, 0.5961, 0.5882],\n",
      "         [0.8588, 0.8745, 0.8784,  ..., 0.5765, 0.5725, 0.5686],\n",
      "         [0.8627, 0.8784, 0.8824,  ..., 0.5686, 0.5765, 0.5843]],\n",
      "\n",
      "        [[0.9529, 0.9608, 0.9686,  ..., 0.9137, 0.8863, 0.8706],\n",
      "         [0.9529, 0.9608, 0.9686,  ..., 0.9294, 0.9098, 0.8941],\n",
      "         [0.9569, 0.9608, 0.9647,  ..., 0.9255, 0.9059, 0.8902],\n",
      "         ...,\n",
      "         [0.8863, 0.8980, 0.9059,  ..., 0.6235, 0.6118, 0.6039],\n",
      "         [0.8863, 0.9020, 0.9098,  ..., 0.5922, 0.5882, 0.5843],\n",
      "         [0.8902, 0.9059, 0.9137,  ..., 0.5843, 0.5922, 0.6000]]]), 23)\n"
     ]
    }
   ],
   "source": [
    "blaBla = trainval_set[1]\n",
    "print(blaBla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is funky beyond my comprehension. Why can I all of a sudden not iterate on the loaders??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 512, 512])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "train_iter = iter(train_loader)\n",
    "bla = train_iter.next()\n",
    "print(bla[0].shape)\n",
    "print(bla[1].shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05908db61d562b6b82dbdd69656403b30dae77f547a66d972e99027ce19f097c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Bachelor_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
