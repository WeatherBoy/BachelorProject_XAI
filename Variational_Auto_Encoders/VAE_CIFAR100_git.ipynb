{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE with the CIFAR100 dataset\n",
    "Training of a VAE on the Cifardataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets, utils, models\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from ignite.handlers.param_scheduler import create_lr_scheduler_with_warmup \n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "\n",
    "## !! For Checkpointing!!!\n",
    "\n",
    "# Path to saving the model\n",
    "save_model_path = \"../trainedModels/VAE_CIFAR100_6.pth\"\n",
    "save_loss_path = \"../plottables/VAE_CIFAR100_6.pth\"\n",
    "\n",
    "## WARNING!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# This boolean will completely wipe any past checkpoints or progress.\n",
    "# ASSIGN IT WITH CARE.\n",
    "completelyRestartTrain = True\n",
    "\n",
    "## Important if you want to train again, set this to True\n",
    "tryResumeTrain = True\n",
    "\n",
    "# Inarguably a weird place to initialize the number of epochs\n",
    "# but it is a magic tool that will come in handy later.\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {DEVICE} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msg(\n",
    "    message: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        message (str): a message of type string, which will be printed to the terminal\n",
    "            with some decoration.\n",
    "\n",
    "    Description:\n",
    "        This function takes a message and prints it nicely\n",
    "\n",
    "    Output:\n",
    "        This function has no output, it prints directly to the terminal\n",
    "    \"\"\"\n",
    "\n",
    "    # word_list makes sure that the output of msg is more readable\n",
    "    sentence_list = message.split(sep=\"\\n\")\n",
    "    # the max-function can apparently be utilised like this:\n",
    "    longest_sentence = max(sentence_list, key=len)\n",
    "\n",
    "    n = len(longest_sentence)\n",
    "    n2 = n // 2 - 1\n",
    "    print(\">\" * n2 + \"  \" + \"<\" * n2)\n",
    "    print(message)\n",
    "    print(\">\" * n2 + \"  \" + \"<\" * n2 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 #128\n",
    "VALIDATION_SPLIT = 0.2\n",
    "RANDOM_SEED = 42\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# Setting seeds ##############################################\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "##############################################################\n",
    "\n",
    "CIFAR100_MEAN = [0.5070751592371323, 0.48654887331495095, 0.4409178433670343]\n",
    "CIFAR100_STD = [0.2673342858792401, 0.2564384629170883, 0.27615047132568404]\n",
    "\n",
    "transform_train = torchvision.transforms.Compose([\n",
    "        #torchvision.transforms.RandomCrop(32, padding=4),\n",
    "        #torchvision.transforms.RandomHorizontalFlip(),\n",
    "        #torchvision.transforms.RandomRotation(15),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(CIFAR100_MEAN, CIFAR100_STD)\n",
    "    ])\n",
    "\n",
    "transform_test = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(CIFAR100_MEAN, CIFAR100_STD)\n",
    "    ])\n",
    "\n",
    "trainval_set = datasets.CIFAR100(\n",
    "    root = '../data/datasetCIFAR100',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(),#transform_train, # \n",
    "    download = True\n",
    "    )\n",
    "\n",
    "test_set = datasets.CIFAR100(\n",
    "    root = '../data/datasetCIFAR100', \n",
    "    train = False, \n",
    "    transform = ToTensor() #transform_test \n",
    "    )\n",
    "\n",
    "train_num = int(len(trainval_set) * (1 - VALIDATION_SPLIT))\n",
    "train_set, val_set = random_split(trainval_set, [train_num, len(trainval_set) - train_num])\n",
    "msg(\"Split train data into trainset and validation set.\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "\n",
    "classes = trainval_set.classes # or class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model and train\n",
    "\n",
    "Models from [here](https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py) and VAE structure from here [git](https://github.com/Jackson-Kang/Pytorch-VAE-tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'Small': [16, 'M', 32, 'M', 32, 'M', 64, 'M', 64, 'M'],\n",
    "    'VGG9': [64, 'M', 128, 'M', 256, 256, 'M', 512, 'M', 512, 'M'],\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vgg_name, input_dim, latent_dim):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.FC_mean = nn.Conv2d(cfg[vgg_name][-2], latent_dim, kernel_size=1, stride=1, padding=0,) # NOTE: -2 because last element is always \"M\"\n",
    "        self.FC_logvar = nn.Conv2d(cfg[vgg_name][-2], latent_dim, kernel_size=1, stride=1, padding=0,)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        #out = out.view(out.size(0), -1) # Flatten(?)\n",
    "        mean = self.FC_mean(out)\n",
    "        #mean = mean.reshape(mean.size(0), mean.size(1), -1).unsqueeze(-1)\n",
    "        #mean = torch.mean(mean, dim=-1, keepdim=True).unsqueeze(-1) # batchSize, latent, 1, 1\n",
    "\n",
    "        log_var = self.FC_logvar(out)\n",
    "        #log_var = log_var.reshape(log_var.size(0), log_var.size(1), -1).unsqueeze(-1) \n",
    "        #log_var = torch.mean(log_var, dim=-1, keepdim=True).unsqueeze(-1) # batchSize, latent, 1, 1\n",
    "        return mean, log_var\n",
    "      \n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = self.input_dim\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.GELU()] # changed from ReLU\n",
    "                in_channels = x\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    # Tjek Forward, og gÃ¥r den fra lille til stor?\n",
    "    def __init__(self, vgg_name, latent_dim, output_dim):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "        #cfg[vgg_name] = [latent_dim,*cfg[vgg_name]] # first layer always input size of image\n",
    "        self.latent_dim = latent_dim\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.FC_output = nn.Conv2d(cfg[vgg_name][-2], output_dim, kernel_size=1) # when kernel size is set to 1, this is indeed a FC layer:)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out  = self.features(x)\n",
    "        #print(out.size())\n",
    "        #out = out.view(out.size(0), -1)\n",
    "        x_hat = torch.sigmoid(self.FC_output(out)) #  without activation function? self.FC_output(out)\n",
    "        \n",
    "        return x_hat\n",
    "    \n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        tot = len(cfg)\n",
    "        in_channels = self.latent_dim\n",
    "        for i in range(tot):\n",
    "            if cfg[i] == 'M': # cfg[tot-i-1] or cfg[i]  \n",
    "                layers += [nn.ConvTranspose2d(cfg[i-1], cfg[i-1], kernel_size=2, stride=2)] # in decoder, we should upsample the image, instead of downsample it\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, cfg[i], kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(cfg[i]),\n",
    "                           nn.GELU()] # changed from ReLU\n",
    "                in_channels = cfg[i]\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(Model, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "\n",
    "    def reparameterization(self, mean, logvar):\n",
    "        std = torch.exp(0.5*logvar) # remember exp(log(sqrt(var))) = exp(0.5*log(var))\n",
    "        eps = torch.randn(std.size(), device=DEVICE)\n",
    "        return (mean + eps*std)\n",
    "    \n",
    "                \n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.Encoder(x)\n",
    "        z = self.reparameterization(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var)\n",
    "        \n",
    "        # also here, unflatten()\n",
    "        z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "        \n",
    "        x_hat = self.Decoder(z)\n",
    "        #test = self.Decoder(mean)\n",
    "        \n",
    "        return x_hat, mean, log_var#, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weird classs - warmUp stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "class WarmUpLR(_LRScheduler):\n",
    "    \"\"\"warmup_training learning rate scheduler\n",
    "    Args:\n",
    "        optimizer: optimzier(e.g. SGD)\n",
    "        total_iters: totoal_iters of warmup phase\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, total_iters, last_epoch=-1):\n",
    "\n",
    "        self.total_iters = total_iters\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "        \n",
    "\n",
    "    def get_lr(self):\n",
    "        \"\"\"we will use the first m batches, and set the learning\n",
    "        rate to base_lr * m / total_iters\n",
    "        \"\"\"\n",
    "        return [base_lr * self.last_epoch / (self.total_iters + 1e-8) for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "channel_size = test_set[0][0].shape[0] #Fixed, dim 0 is the feature channel number\n",
    "latent_dim = 10 #From 5 # hyperparameter\n",
    "\n",
    "WARMUP_ITERATIONS = 10\n",
    "WEIGHT_DECAY = 1e-4\n",
    "SGD_MOMENTUM = 0.9\n",
    "INITIAL_LR = 1e-3\n",
    "\n",
    "numEpochs = 100\n",
    "modeltype = 'Small'\n",
    "\n",
    "encoder = Encoder(modeltype,  input_dim=channel_size,     latent_dim=latent_dim).to(DEVICE)\n",
    "decoder = Decoder(modeltype,  latent_dim=latent_dim,   output_dim = channel_size).to(DEVICE)\n",
    "\n",
    "model = Model(Encoder=encoder, Decoder=decoder).to(DEVICE)\n",
    "\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr = INITIAL_LR, weight_decay=WEIGHT_DECAY)#optim.SGD(model.parameters(), lr= lr)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=INITIAL_LR, \n",
    "                            momentum=SGD_MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "iter_per_epoch = len(train_loader)\n",
    "warmup_scheduler = WarmUpLR(optimizer, iter_per_epoch * WARMUP_ITERATIONS)        \n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=numEpochs-WARMUP_ITERATIONS)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"hyperparameters are:\")\n",
    "msg(f\"latent space dim: \\t{latent_dim} \\nlearning rate \\t\\t{INITIAL_LR} \\nmodel type \\t\\t{modeltype}\\nNumber of epoch \\t{numEpochs} \\nBatch size \\t\\t{BATCH_SIZE} \\nWeight decay \\t\\t{WEIGHT_DECAY}\\nWarmup \\t\\t\\t{WARMUP_ITERATIONS}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DimCheck = True\n",
    "\n",
    "if DimCheck == False:\n",
    "    x = torch.randn(2,3,32,32)\n",
    "    print(f\"Size of input {x.size()}\")\n",
    "    # Encoder test\n",
    "    mean, logvar = encoder(x)\n",
    "    print(f\"The mean shape {mean.size()}, \\tthe variance shape {logvar.size()}\")\n",
    "\n",
    "    # reparm  trick\n",
    "    std = torch.exp(0.5*logvar) # e^log(sqrt(sigma^2)) = e^(0.5*sigma^2) = sigma\n",
    "    eps = torch.randn(std.size()) \n",
    "    z = mean + eps*std\n",
    "\n",
    "    x_hat = decoder(z)\n",
    "\n",
    "    print(f\"Latent vector size: {z.size()}, \\tand x_hat {x_hat.size()}\")\n",
    "\n",
    "    # Model pred\n",
    "    x_hat, mean, logvar = model(x)\n",
    "    \n",
    "    repoloss = nn.functional.binary_cross_entropy(x_hat, x)\n",
    "    KLD_loss = torch.mean( -0.5 * torch.sum(1+ logvar - mean**2 - logvar.exp(),dim=1),dim = 0)\n",
    "    loss = repoloss + KLD_loss\n",
    "\n",
    "    # # Grad type?\n",
    "    # print(f\"Repo loss grad type: {repoloss.grad_fn}\")\n",
    "    # print(f\"KLD loss grad type: {KLD_loss.grad_fn}\")\n",
    "    # print(f\"loss grad type: {loss.grad_fn}\")\n",
    "\n",
    "\n",
    "    # print(f\"loss: repo: {repoloss :>7f}\\t KLD: {KLD_loss}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpointing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is important that it is initialized to zero\n",
    "# if we are in the case that a model hasn't been trained yet.\n",
    "loss_train = np.zeros((2, numEpochs))\n",
    "loss_val = np.zeros((2, numEpochs))\n",
    "            \n",
    "# exists is a function from os.path (standard library)\n",
    "trained_model_exists = exists(save_model_path)\n",
    "\n",
    "if trained_model_exists:\n",
    "    if completelyRestartTrain:\n",
    "        os.remove(save_model_path)\n",
    "        startEpoch = 0\n",
    "        msg(\"Previous model was deleted. \\nRestarting training.\")\n",
    "    else:\n",
    "        import collections\n",
    "        if not (type(torch.load(save_model_path)) is collections.OrderedDict):\n",
    "            ## If it looks stupid but works it ain't stupid B)\n",
    "            #\n",
    "            # I think if it isn't that datatype, then it saved the Alex-way\n",
    "            # and then we can load stuff.\n",
    "            # Because if it is that datatype then it is for sure \"just\" the state_dict.\n",
    "            \n",
    "            checkpoint = torch.load(save_model_path)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            \n",
    "            num_previous_epochs = checkpoint['accuracies'].shape[1]\n",
    "            \n",
    "            if num_previous_epochs < numEpochs:\n",
    "                # if we trained to fewer epochs previously,\n",
    "                # now we train to the proper amount, therfore padded zeroes are required.\n",
    "                remainingZeros = np.zeros((2,numEpochs-num_previous_epochs))\n",
    "                checkpoint['accuracies'] = np.concatenate((checkpoint['accuracies'], remainingZeros), axis=1)\n",
    "                checkpoint['losses'] = np.concatenate((checkpoint['losses'], remainingZeros), axis=1)\n",
    "                \n",
    "            if numEpochs < num_previous_epochs:\n",
    "                # Just cut off our data at the required amount of epochs, so nothing looks funky.\n",
    "                checkpoint['accuracies'] = checkpoint['accuracies'][:,:numEpochs]\n",
    "                checkpoint['losses'] = checkpoint['losses'][:,:numEpochs]\n",
    "            \n",
    "            # we save at the epoch we completed, but we wan't to start at the following epoch\n",
    "            startEpoch = checkpoint['epoch'] + 1 \n",
    "            \n",
    "            if startEpoch < numEpochs:\n",
    "                # we add one to startEpoch here (in the message) to make up for\n",
    "                # the for-loop being zero-indexed.\n",
    "                msg(f\"Model will resume training from epoch: {startEpoch + 1}\")\n",
    "                \n",
    "                # grapping our accuracies from the previously trained model\n",
    "                accuracies = checkpoint['accuracies']\n",
    "                losses = checkpoint['losses']\n",
    "                \n",
    "            elif tryResumeTrain and startEpoch >= numEpochs:\n",
    "                msg(\"Model has already finished training. \"\n",
    "                    + \"\\nDo you wan't to delete previous model and start over?\")\n",
    "                userInput = input(\"Input [y/n]:\\t\")\n",
    "                while userInput.lower() != 'y' and userInput.lower != 'n':\n",
    "                    userInput = input(\"You must input either 'y' (yes) or 'n' (no):\\t\")\n",
    "                if userInput.lower() == \"y\":\n",
    "                    os.remove(save_model_path)\n",
    "                    startEpoch = 0\n",
    "                    msg(\"Previous model was deleted. \\nRestarting training!\")\n",
    "                elif userInput.lower() == \"n\":\n",
    "                    msg(\"Model had already finished training and no new training will commence.\")\n",
    "                    \n",
    "            elif not tryResumeTrain and startEpoch >= numEpochs:\n",
    "                msg(f\"Model finished training at epoch: {startEpoch}\")\n",
    "                # grapping our accuracies from the previously trained model\n",
    "                accuracies = checkpoint['accuracies']\n",
    "                losses = checkpoint['losses']\n",
    "                            \n",
    "else:\n",
    "    #Trained model doesn't exist\n",
    "    msg(\"There was no previously existing model. \\nTraining will commence from beginning.\")\n",
    "    startEpoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "In CIFAR100. First define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_function(x, x_hat, mean, log_var, KLD_scale):\n",
    "    reproduction_loss = nn.MSELoss()(x_hat, x)\n",
    "    #KLD      = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "    KLD = torch.mean( -0.5 * torch.sum(1+ log_var - mean**2 - log_var.exp(),dim=1),dim = 0) # Mean loss for the whole batch\n",
    "    KLD *=  KLD_scale\n",
    "    \n",
    "    #print(f\"Reproduction: {reproduction_loss}, \\tKLD: {KLD.item()}, \\tscaled KLD: {(KLD * scale).item()}, \\tlog_var: {log_var.sum()}\")\n",
    "    return reproduction_loss, KLD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and testing loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, loader, loss_fn, optimizer, KLD_scale):\n",
    "    model.train()\n",
    "\n",
    "    size = len(loader.dataset)\n",
    "    train_avg_KLD = 0\n",
    "    train_avg_repo = 0\n",
    "    num_batches = len(loader)\n",
    "\n",
    "    for batch_idx, (x, _) in enumerate(loader):\n",
    "        \n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        # Model pred\n",
    "        x_hat, mean, log_var = model(x)\n",
    "\n",
    "        # Compute loss\n",
    "        loss_repo, loss_KLD = loss_fn(x, x_hat, mean, log_var, KLD_scale)\n",
    "        loss = loss_repo + loss_KLD\n",
    "\n",
    "        train_avg_repo += loss_repo.item()\n",
    "        train_avg_KLD += loss_KLD.item()\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        current_batch_size = len(x)\n",
    "        \n",
    "        # Check gradient and loss\n",
    "        if (batch_idx + 1) % (5000//current_batch_size) == 0 or batch_idx == 0:\n",
    "            # Print loss\n",
    "            loss, current = loss.item(), batch_idx * current_batch_size\n",
    "            print(f\"loss: repo: {loss_repo.item() :>4f}\\t KLD scaled: {loss_KLD.item() :>4f}  [{current+1:>5d}/{size:>5d}]\")\n",
    "\n",
    "            if model.Encoder.features[0].weight.grad == None:\n",
    "                print(\"No gradient...?\")\n",
    "            #else:\n",
    "                \n",
    "            #    print(f\"Gadient first layer at step, \\nmin: {model.Encoder.features[0].weight.grad.data.min() :>5f} \\t max: {model.Encoder.features[0].weight.grad.data.max() :>5f}\\n\") # FC_logvar.weight.grad \n",
    "        if epoch <= WARMUP_ITERATIONS:\n",
    "            warmup_scheduler.step()\n",
    "        \n",
    "    train_avg_repo /= num_batches\n",
    "    train_avg_KLD /= num_batches\n",
    "\n",
    "    return train_avg_repo, train_avg_KLD\n",
    "\n",
    "def test_loop(model, loader, loss_fn, KLD_scale):\n",
    "    model.eval()\n",
    "\n",
    "    num_batches = len(loader)\n",
    "    val_avg_KLD = 0\n",
    "    val_avg_repo = 0\n",
    "    with torch.no_grad():\n",
    "        for (x,_) in loader:\n",
    "            # Get data\n",
    "            x = x.to(DEVICE)\n",
    "\n",
    "            # Compute loss\n",
    "            x_hat, mean, log_var = model(x)\n",
    "            loss_repo, loss_KLD = loss_fn(x, x_hat, mean, log_var, KLD_scale)\n",
    "\n",
    "            val_avg_repo += loss_repo.item()\n",
    "            val_avg_KLD += loss_KLD.item()\n",
    "\n",
    "    val_avg_repo /= num_batches\n",
    "    val_avg_KLD /= num_batches\n",
    "    return val_avg_repo, val_avg_KLD \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the training begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not trained_model_exists or tryResumeTrain or startEpoch < (numEpochs - 1):\n",
    "    best_loss = np.inf\n",
    "\n",
    "    msg(\"Will now begin training!\")\n",
    "    for epoch in range(startEpoch,numEpochs):\n",
    "        if epoch > WARMUP_ITERATIONS:\n",
    "            # TODO make sure it matches scheduler\n",
    "            scheduler.step()\n",
    "        KLD_scale = (epoch + 1)/np.power(numEpochs,2)\n",
    "        print(f\"Epoch {epoch +1}\\n----------------------------------\")\n",
    "        train_avg_repo, train_avg_KLD   = train_loop(model, train_loader, loss_function, optimizer, KLD_scale)\n",
    "        val_avg_repo, val_avg_KLD       = test_loop(model, val_loader, loss_function, KLD_scale)\n",
    "\n",
    "        # Save information for plotting\n",
    "        loss_train[0,epoch], loss_train[1,epoch]    = train_avg_repo, train_avg_KLD\n",
    "        loss_val[0, epoch], loss_val[1, epoch]      = val_avg_repo, val_avg_KLD     \n",
    "        avg_loss_val = val_avg_repo + val_avg_KLD\n",
    "\n",
    "        if avg_loss_val < best_loss:\n",
    "            # We only save a checkpoint if our model is performing better\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, save_model_path)\n",
    "            best_loss = avg_loss_val\n",
    "\n",
    "            msg(f\"New best loss is: {avg_loss_val} \\nCheckpoint at epoch: {epoch + 1}\")\n",
    "        else:\n",
    "            msg(\"Only test and val losses were updated\")\n",
    "        \n",
    "        torch.save({\"train_loss\" : loss_train, \"val_loss\" : loss_val}, save_loss_path)\n",
    "            \n",
    "    msg(f\"Done! Final model was saved to: \\n'{save_model_path}'\")\n",
    "    \n",
    "else:\n",
    "    msg(\"Have already trained this model once!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot reproduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model_path = \"VAE_CIFAR100_4.pth\"#\"VAE_CIFAR100_linVGG16.pth-kopi\"#/Users/Alex/Documents/results/savedModel/VAE_CIFAR100_linVGG16.pth\"#\"VAE_CIFAR100.pth\"\n",
    "checkpoint = torch.load(my_model_path, map_location=torch.device(DEVICE))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "invert_normalization = torchvision.transforms.Compose([\n",
    "         torchvision.transforms.Normalize(mean = [0, 0, 0], std = 1/CIFAR100_STD),\n",
    "         torchvision.transforms.Normalize(mean = -1*CIFAR100_MEAN, std = [1,1,1])])\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "\n",
    "def batchplot(batch_show,image):\n",
    "# How many images from the batch will you show?\n",
    "\n",
    "\n",
    "    def imshow(img):\n",
    "        #img = img / 2 + 0.5     # unnormalize\n",
    "            npimg = img.numpy()\n",
    "            plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "            #plt.show()\n",
    "\n",
    "    \n",
    "    # Model reconstruction\n",
    "    mean, logvar =model.Encoder(image)\n",
    "    z = mean + torch.exp(0.5*logvar) \n",
    "    x_hat = model.Decoder(z)\n",
    "\n",
    "    x.transform(invert_normalization)\n",
    "\n",
    "    fig1=plt.figure(figsize=(17,4))\n",
    "    fig1.patch.set_facecolor('white')\n",
    "    for i in range(batch_show):\n",
    "\n",
    "        plt.subplot(2,batch_show,i+1)\n",
    "        imshow(image[i])\n",
    "        plt.xticks([],[])\n",
    "        plt.yticks([],[])\n",
    "        plt.title(classes[labels[i].item()])\n",
    "        if i == 0:\n",
    "            plt.ylabel('Original image')\n",
    "        \n",
    "        plt.subplot(2,batch_show,batch_show+ i+1)\n",
    "        imshow(x_hat[i].detach())\n",
    "        plt.xticks([],[])\n",
    "        plt.yticks([],[])\n",
    "        if i == 0:\n",
    "            plt.ylabel('Reproduced image')\n",
    "    pass\n",
    "\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "x, labels = dataiter.next()\n",
    "\n",
    "batch_show = 7\n",
    "\n",
    "batchplot(batch_show,x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to python file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook VAE_CIFAR100_test.ipynb to script\n",
      "[NbConvertApp] Writing 21778 bytes to VAE_CIFAR100_test.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script VAE_CIFAR100_test.ipynb"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d806fedfadc4f43df997bb69e69664c5753a645548adea2a58a56079e3db770c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
