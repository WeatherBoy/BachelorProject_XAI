{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE with the CIFAR100 dataset\n",
    "Training of a VAE on the Cifardataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import datasets, utils, models\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "\n",
    "## !! For Checkpointing!!!\n",
    "\n",
    "# Path to saving the model\n",
    "saveModelPath = \"../trainedModels/VAE_CIFAR100.pth\"\n",
    "\n",
    "## WARNING!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# This boolean will completely wipe any past checkpoints or progress.\n",
    "# ASSIGN IT WITH CARE.\n",
    "completelyRestartTrain = True\n",
    "\n",
    "## Important if you want to train again, set this to True\n",
    "tryResumeTrain = True\n",
    "\n",
    "# Inarguably a weird place to initialize the number of epochs\n",
    "# but it is a magic tool that will come in handy later.\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {DEVICE} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msg(\n",
    "    message: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        message (str): a message of type string, which will be printed to the terminal\n",
    "            with some decoration.\n",
    "\n",
    "    Description:\n",
    "        This function takes a message and prints it nicely\n",
    "\n",
    "    Output:\n",
    "        This function has no output, it prints directly to the terminal\n",
    "    \"\"\"\n",
    "\n",
    "    # word_list makes sure that the output of msg is more readable\n",
    "    sentence_list = message.split(sep=\"\\n\")\n",
    "    # the max-function can apparently be utilised like this:\n",
    "    longest_sentence = max(sentence_list, key=len)\n",
    "\n",
    "    n = len(longest_sentence)\n",
    "    n2 = n // 2 - 1\n",
    "    print(\">\" * n2 + \"  \" + \"<\" * n2)\n",
    "    print(message)\n",
    "    print(\">\" * n2 + \"  \" + \"<\" * n2 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>  <<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Split train data into trainset and validation set.\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>  <<<<<<<<<<<<<<<<<<<<<<<<\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32 #128\n",
    "VALIDATION_SPLIT = 0.2\n",
    "RANDOM_SEED = 42\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# Setting seeds ##############################################\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "##############################################################\n",
    "\n",
    "trainval_set = datasets.CIFAR100(\n",
    "    root = '../data/datasetCIFAR100',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True\n",
    "    )\n",
    "\n",
    "test_set = datasets.CIFAR100(\n",
    "    root = '../data/datasetCIFAR100', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    "    )\n",
    "\n",
    "train_num = int(len(trainval_set) * (1 - VALIDATION_SPLIT))\n",
    "train_set, val_set = random_split(trainval_set, [train_num, len(trainval_set) - train_num])\n",
    "msg(\"Split train data into trainset and validation set.\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "\n",
    "classes = trainval_set.classes # or class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model and train\n",
    "\n",
    "Models from [here](https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py) and VAE structure from here [git](https://github.com/Jackson-Kang/Pytorch-VAE-tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG9': [64, 'M', 128, 'M', 256, 256, 'M', 512, 'M', 512, 'M'],\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vgg_name, input_dim, latent_dim):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.FC_mean = nn.Conv2d(cfg[vgg_name][-2], latent_dim, kernel_size=1) # NOTE: -2 because last element is always \"M\"\n",
    "        self.FC_logvar = nn.Conv2d(cfg[vgg_name][-2], latent_dim, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        #out = out.view(out.size(0), -1) # Flatten(?)\n",
    "        mean = self.FC_mean(out)\n",
    "        mean = mean.reshape(mean.size(0), mean.size(1), -1)\n",
    "        mean = torch.mean(mean, dim=-1, keepdim=True).unsqueeze(-1) # batchSize, latent, 1, 1\n",
    "\n",
    "        log_var = self.FC_logvar(out)\n",
    "        log_var = log_var.reshape(log_var.size(0), log_var.size(1), -1)\n",
    "        log_var = torch.mean(log_var, dim=-1, keepdim=True).unsqueeze(-1) # batchSize, latent, 1, 1\n",
    "        return mean, log_var\n",
    "      \n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = self.input_dim\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.GELU()] # changed from ReLU\n",
    "                in_channels = x\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    # Tjek Forward, og gÃ¥r den fra lille til stor?\n",
    "    def __init__(self, vgg_name, latent_dim, output_dim):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "        #cfg[vgg_name] = [latent_dim,*cfg[vgg_name]] # first layer always input size of image\n",
    "        self.latent_dim = latent_dim\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.FC_output = nn.Conv2d(cfg[vgg_name][-2], output_dim, kernel_size=1) # when kernel size is set to 1, this is indeed a FC layer:)\n",
    "        # self.FC_output = nn.Linear(cfg[vgg_name][-2], output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out  = self.features(x)\n",
    "        #print(out.size())\n",
    "        #out = out.view(out.size(0), -1)\n",
    "        x_hat = torch.sigmoid(self.FC_output(out)) #  without activation function? self.FC_output(out)\n",
    "        \n",
    "        return x_hat\n",
    "    \n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        tot = len(cfg)\n",
    "        in_channels = self.latent_dim\n",
    "        for i in range(tot):\n",
    "            if cfg[i] == 'M': # cfg[tot-i-1] or cfg[i]  \n",
    "                layers += [nn.ConvTranspose2d(cfg[i-1], cfg[i-1], kernel_size=2, stride=2)] # in decoder, we should upsample the image, instead of downsample it\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, cfg[i], kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(cfg[i]),\n",
    "                           nn.LeakyReLU()] # changed from ReLU\n",
    "                in_channels = cfg[i]\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(Model, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "\n",
    "    def reparameterization(self, mean, logvar):\n",
    "        std = torch.exp(0.5*logvar) # remember exp(log(sqrt(var))) = exp(0.5*log(var))\n",
    "        eps = torch.rand_like(std)\n",
    "        return (mean + eps*std)\n",
    "        \n",
    "                \n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.Encoder(x)\n",
    "        z = self.reparameterization(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var)\n",
    "        \n",
    "        # also here, unflatten()\n",
    "        z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "        \n",
    "        x_hat = self.Decoder(z)\n",
    "        \n",
    "        return x_hat, mean, log_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameters are:\n",
      ">>>>>>>>>>  <<<<<<<<<<\n",
      "latent space dim: \t256 \n",
      "learning rate \t\t1e-05 \n",
      "model type \t\tVGG11\n",
      "Number of epoch \t30\n",
      ">>>>>>>>>>  <<<<<<<<<<\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "channel_size = test_set[0][0].shape[0] #Fixed, dim 0 is the feature channel number\n",
    "latent_dim = 128 # hyperparameter\n",
    "lr = 1e-4\n",
    "numEpochs = 30\n",
    "modeltype = 'VGG11'\n",
    "\n",
    "encoder = Encoder(modeltype,  input_dim=channel_size,     latent_dim=latent_dim)\n",
    "decoder = Decoder(modeltype,  latent_dim=latent_dim,   output_dim = channel_size)\n",
    "\n",
    "model = Model(Encoder=encoder, Decoder=decoder).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)#optim.SGD(model.parameters(), lr= lr)\n",
    "\n",
    "print(f\"hyperparameters are:\")\n",
    "msg(f\"latent space dim: \\t{latent_dim} \\nlearning rate \\t\\t{lr} \\nmodel type \\t\\t{modeltype}\\nNumber of epoch \\t{numEpochs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DimCheck = False\n",
    "\n",
    "if DimCheck == True:\n",
    "    x = torch.randn(2,3,32,32)\n",
    "    print(f\"size of input{x.size()}\")\n",
    "    # Encoder test\n",
    "    mean, logvar = encoder(x)\n",
    "    print(f\"The mean shape {mean.size()}, \\nthe variance shape {logvar.size()}\")\n",
    "\n",
    "    # reparm  trick\n",
    "    std = torch.exp(0.5*logvar) # e^log(sqrt(sigma^2)) = e^(0.5*sigma^2) = sigma\n",
    "    eps = torch.rand_like(std) \n",
    "    z = mean + eps*std\n",
    "\n",
    "    x_hat = decoder(z)\n",
    "\n",
    "    print(f\"Latent vector size: {z.size()}, and x_hat {x_hat.size()}\")\n",
    "\n",
    "    # Model pred\n",
    "    x_hat, mean, logvar = model(x)\n",
    "    \n",
    "    repoloss = nn.functional.binary_cross_entropy(x_hat, x)\n",
    "    KLD_loss = torch.mean( -0.5 * torch.sum(1+ logvar - mean**2 - logvar.exp(),dim=1),dim = 0)\n",
    "    loss = repoloss + KLD_loss\n",
    "\n",
    "    # Grad?\n",
    "    print(f\"Repo loss grad type: {repoloss.grad_fn}\")\n",
    "    print(f\"KLD loss grad type: {KLD_loss.grad_fn}\")\n",
    "    print(f\"loss grad type: {loss.grad_fn}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpointing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>>  <<<<<<<<<<<<<<<<<<<\n",
      "There was no previously existing model. \n",
      "Training will commence from beginning.\n",
      ">>>>>>>>>>>>>>>>>>>  <<<<<<<<<<<<<<<<<<<\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It is important that it is initialized to zero\n",
    "# if we are in the case that a model hasn't been trained yet.\n",
    "accuracies = np.zeros((2, numEpochs))\n",
    "losses = np.zeros((2, numEpochs))\n",
    "            \n",
    "# exists is a function from os.path (standard library)\n",
    "trained_model_exists = exists(saveModelPath)\n",
    "\n",
    "if trained_model_exists:\n",
    "    if completelyRestartTrain:\n",
    "        os.remove(saveModelPath)\n",
    "        startEpoch = 0\n",
    "        msg(\"Previous model was deleted. \\nRestarting training.\")\n",
    "    else:\n",
    "        import collections\n",
    "        if not (type(torch.load(saveModelPath)) is collections.OrderedDict):\n",
    "            ## If it looks stupid but works it ain't stupid B)\n",
    "            #\n",
    "            # I think if it isn't that datatype, then it saved the Alex-way\n",
    "            # and then we can load stuff.\n",
    "            # Because if it is that datatype then it is for sure \"just\" the state_dict.\n",
    "            \n",
    "            checkpoint = torch.load(saveModelPath)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            \n",
    "            num_previous_epochs = checkpoint['accuracies'].shape[1]\n",
    "            \n",
    "            if num_previous_epochs < numEpochs:\n",
    "                # if we trained to fewer epochs previously,\n",
    "                # now we train to the proper amount, therfore padded zeroes are required.\n",
    "                remainingZeros = np.zeros((2,numEpochs-num_previous_epochs))\n",
    "                checkpoint['accuracies'] = np.concatenate((checkpoint['accuracies'], remainingZeros), axis=1)\n",
    "                checkpoint['losses'] = np.concatenate((checkpoint['losses'], remainingZeros), axis=1)\n",
    "                \n",
    "            if numEpochs < num_previous_epochs:\n",
    "                # Just cut off our data at the required amount of epochs, so nothing looks funky.\n",
    "                checkpoint['accuracies'] = checkpoint['accuracies'][:,:numEpochs]\n",
    "                checkpoint['losses'] = checkpoint['losses'][:,:numEpochs]\n",
    "            \n",
    "            # we save at the epoch we completed, but we wan't to start at the following epoch\n",
    "            startEpoch = checkpoint['epoch'] + 1 \n",
    "            \n",
    "            if startEpoch < numEpochs:\n",
    "                # we add one to startEpoch here (in the message) to make up for\n",
    "                # the for-loop being zero-indexed.\n",
    "                msg(f\"Model will resume training from epoch: {startEpoch + 1}\")\n",
    "                \n",
    "                # grapping our accuracies from the previously trained model\n",
    "                accuracies = checkpoint['accuracies']\n",
    "                losses = checkpoint['losses']\n",
    "                \n",
    "            elif tryResumeTrain and startEpoch >= numEpochs:\n",
    "                msg(\"Model has already finished training. \"\n",
    "                    + \"\\nDo you wan't to delete previous model and start over?\")\n",
    "                userInput = input(\"Input [y/n]:\\t\")\n",
    "                while userInput.lower() != 'y' and userInput.lower != 'n':\n",
    "                    userInput = input(\"You must input either 'y' (yes) or 'n' (no):\\t\")\n",
    "                if userInput.lower() == \"y\":\n",
    "                    os.remove(saveModelPath)\n",
    "                    startEpoch = 0\n",
    "                    msg(\"Previous model was deleted. \\nRestarting training!\")\n",
    "                elif userInput.lower() == \"n\":\n",
    "                    msg(\"Model had already finished training and no new training will commence.\")\n",
    "                    \n",
    "            elif not tryResumeTrain and startEpoch >= numEpochs:\n",
    "                msg(f\"Model finished training at epoch: {startEpoch}\")\n",
    "                # grapping our accuracies from the previously trained model\n",
    "                accuracies = checkpoint['accuracies']\n",
    "                losses = checkpoint['losses']\n",
    "                            \n",
    "else:\n",
    "    #Trained model doesn't exist\n",
    "    msg(\"There was no previously existing model. \\nTraining will commence from beginning.\")\n",
    "    startEpoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "In CIFAR100. First define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.MSELoss()(x_hat, x)\n",
    "    #KLD      = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "    KLD = torch.mean( -0.5 * torch.sum(1+ log_var - mean**2 - log_var.exp(),dim=1),dim = 0) # Mean loss for the whole batch\n",
    "    scale = 0.1 #0.00025\n",
    "    \n",
    "    #print(f\"Reproduction: {reproduction_loss}, \\tKLD: {KLD.item()}, \\tscaled KLD: {(KLD * scale).item()}, \\tlog_var: {log_var.sum()}\")\n",
    "    return reproduction_loss + scale*KLD , {\"repo_loss\": reproduction_loss, \"KLD scalede\" : scale*KLD} #*scale #  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and testing loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, loader, loss_fn, optimizer):\n",
    "    size = len(loader.dataset)\n",
    "    train_avg_loss = 0\n",
    "    num_batches = len(loader)\n",
    "\n",
    "    for batch_idx, (x, _) in enumerate(loader):\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        # Model pred\n",
    "        x_hat, mean, log_var = model(x)\n",
    "\n",
    "        # Compute loss\n",
    "        loss, loss_funcs = loss_fn(x, x_hat, mean, log_var)\n",
    "        train_avg_loss += loss.item()\n",
    "\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        \n",
    "            \n",
    "        current_batch_size = len(x)\n",
    "        # Check gradient\n",
    "        if (batch_idx + 1) % (10000//current_batch_size) == 0:\n",
    "            if model.Encoder.features[0].weight.grad == None:\n",
    "                print(\"No gradient...?\")\n",
    "            else:\n",
    "                \n",
    "                print(f\"Gadient first layer per 500 step, min: {model.Encoder.features[0].weight.grad.data.min()} \\t max: {model.Encoder.features[0].weight.grad.data.max()}\") # FC_logvar.weight.grad \n",
    "          \n",
    "        optimizer.step()\n",
    "        \n",
    "        if False: #(batch_idx + 1) % (500//current_batch_size) == 0:\n",
    "            loss, current = loss.item(), batch_idx * current_batch_size\n",
    "            print(f\"loss: repo: {loss_funcs['repo_loss'] :>7f}\\t KLD: {loss_funcs['KLD'].item()}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "    train_avg_loss /= num_batches\n",
    "    return train_avg_loss\n",
    "\n",
    "def test_loop(model, loader, loss_fn):\n",
    "    num_batches = len(loader)\n",
    "    test_avg_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for (x,_) in loader:\n",
    "            # Get data\n",
    "            x = x.to(DEVICE)\n",
    "\n",
    "            # Compute loss\n",
    "            x_hat, mean, log_var = model(x)\n",
    "            loss, loss_funcs = loss_fn(x, x_hat, mean, log_var)\n",
    "            test_avg_loss += loss.item()\n",
    "\n",
    "    test_avg_loss /= num_batches\n",
    "    return test_avg_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the training begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "----------------------------------\n",
      "Gadient first layer per 500 step, min: -0.0026663586031645536 \t max: 0.0020215529948472977\n"
     ]
    }
   ],
   "source": [
    "if not trained_model_exists or tryResumeTrain or startEpoch < (numEpochs - 1):\n",
    "\n",
    "    for epoch in range(startEpoch,numEpochs):\n",
    "        print(f\"Epoch {epoch +1}\\n----------------------------------\")\n",
    "        train_avg_loss  = train_loop(model, train_loader, loss_function, optimizer)\n",
    "        val_avg_loss    = test_loop(model, val_loader, loss_function)\n",
    "        \n",
    "        print(f\"\\n  average train loss: {val_avg_loss}\")\n",
    "        print(f\"\\n  average valitation loss: {val_avg_loss}\\n\")\n",
    "\n",
    "        # Save information for plotting\n",
    "        losses[0,epoch], losses[1,epoch] = val_avg_loss, train_avg_loss    \n",
    "\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': losses,\n",
    "            }, saveModelPath)\n",
    "        print(f\"Checkpoint at epoch {epoch + 1}\\n\")\n",
    "    msg(f\"Traning is done, final model saved to: \\n'{saveModelPath}'\")\n",
    "else:\n",
    "    msg(\"Have already trained this model once!\")\n",
    "\n",
    "# Save final model \n",
    "torch.save(model.state_dict(), saveModelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot reproduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model.eval()\n",
    "\n",
    "def batchplot(batch_show,image):\n",
    "# How many images from the batch will you show?\n",
    "\n",
    "\n",
    "    def imshow(img):\n",
    "        #img = img / 2 + 0.5     # unnormalize\n",
    "            npimg = img.numpy()\n",
    "            plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "            #plt.show()\n",
    "\n",
    "    # Model reconstruction\n",
    "    x_hat, mean, var = model(image)\n",
    "\n",
    "    fig1=plt.figure(figsize=(17,4))\n",
    "    fig1.patch.set_facecolor('white')\n",
    "    for i in range(batch_show):\n",
    "\n",
    "        plt.subplot(2,batch_show,i+1)\n",
    "        imshow(image[i])\n",
    "        plt.xticks([],[])\n",
    "        plt.yticks([],[])\n",
    "        plt.title(classes[labels[i].item()])\n",
    "        if i == 0:\n",
    "            plt.ylabel('Original image')\n",
    "        \n",
    "\n",
    "        plt.subplot(2,batch_show,batch_show+ i+1)\n",
    "        imshow(x_hat[i].detach())\n",
    "        plt.xticks([],[])\n",
    "        plt.yticks([],[])\n",
    "        if i == 0:\n",
    "            plt.ylabel('Reproduced image')\n",
    "    pass\n",
    "\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "x, labels = dataiter.next()\n",
    "batch_show = 7\n",
    "#batchplot(batch_show,x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to python file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook VAE_CIFAR100_test.ipynb to script\n",
      "[NbConvertApp] Writing 17763 bytes to VAE_CIFAR100_test.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script VAE_CIFAR100_test.ipynb"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d806fedfadc4f43df997bb69e69664c5753a645548adea2a58a56079e3db770c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
