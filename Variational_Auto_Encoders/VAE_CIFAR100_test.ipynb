{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE with the CIFAR100 dataset\n",
    "Link from fiskemad...\n",
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 128 # If you are using GPU, you can set the batch size to be 2, 4, 8, 16, 32..., this makes the GPUs work more effciently!\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='../data/datasetCIFAR100', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='../data/datasetCIFAR100', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = trainset.classes # or class_to_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model and train\n",
    "\n",
    "Models from [here](https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py) and VAE structure from here [git](https://github.com/Jackson-Kang/Pytorch-VAE-tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: jupyter-nbconvert [-h] [--debug] [--generate-config] [-y] [--execute]\n",
      "                         [--allow-errors] [--stdin] [--stdout] [--inplace]\n",
      "                         [--clear-output] [--no-prompt] [--no-input]\n",
      "                         [--allow-chromium-download]\n",
      "                         [--log-level NbConvertApp.log_level]\n",
      "                         [--config NbConvertApp.config_file]\n",
      "                         [--to NbConvertApp.export_format]\n",
      "                         [--template TemplateExporter.template_name]\n",
      "                         [--template-file TemplateExporter.template_file]\n",
      "                         [--writer NbConvertApp.writer_class]\n",
      "                         [--post NbConvertApp.postprocessor_class]\n",
      "                         [--output NbConvertApp.output_base]\n",
      "                         [--output-dir FilesWriter.build_directory]\n",
      "                         [--reveal-prefix SlidesExporter.reveal_url_prefix]\n",
      "                         [--nbformat NotebookExporter.nbformat_version]\n",
      "                         [extra_args [extra_args ...]]\n",
      "jupyter-nbconvert: error: unrecognized arguments: VAE_CIFAR100_test.ipynb!jupyter nbconvert VAE_CIFAR100_test.ipynb!jupyter nbconvert VAE_CIFAR100_test.ipynb!jupyter nbconvert VAE_CIFAR100_test.ipynb!jupyter nbconvert VAE_CIFAR100_test.ipynb!jupyter nbconvert VAE_CIFAR100_test.ipynb!jupyter nbconvert VAE_CIFAR100_test.ipynb!jupyter nbconvert VAE_CIFAR100_test.ipynb!jupaefasfkjbasvdbsdvbdvsbkjdsvkbjjfjnfsajafsn\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "    'VGG9': [64, 'M', 128, 'M', 256, 256, 'M', 512, 'M', 512, 'M'],\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, vgg_name, input_dim, latent_dim):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        cfg[vgg_name] = [input_dim,*cfg[vgg_name]] # first layer always input size of image\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.FC_mean = nn.Conv2d(cfg[vgg_name][-2], latent_dim, kernel_size=1)\n",
    "        self.FC_var = nn.Conv2d(cfg[vgg_name][-2], latent_dim, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        #out = out.view(out.size(0), -1) # Flatten(?)\n",
    "        mean = self.FC_mean(out)\n",
    "        mean = mean.reshape(mean.size(0), mean.size(1), -1)\n",
    "        mean = torch.mean(mean, dim=-1, keepdim=True).unsqueeze(-1) # b, latent, 1, 1\n",
    "\n",
    "        log_var = self.FC_var(out)\n",
    "        log_var = log_var.reshape(log_var.size(0), log_var.size(1), -1)\n",
    "        log_var = torch.mean(log_var, dim=-1, keepdim=True).unsqueeze(-1) # b, latent, 1, 1\n",
    "        return mean, log_var\n",
    "      \n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.GELU()] # changed from ReLU\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vgg_name, latent_dim, output_dim):\n",
    "\n",
    "        super(Decoder, self).__init__()\n",
    "        cfg[vgg_name] = [latent_dim,*cfg[vgg_name]] # first layer always input size of image\n",
    "        self.latent_dim = latent_dim\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.FC_output = nn.Conv2d(cfg[vgg_name][-2], output_dim, kernel_size=1) # when kernel size is set to 1, this is indeed a FC layer:)\n",
    "        # self.FC_output = nn.Linear(cfg[vgg_name][-2], output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out  = self.features(x)\n",
    "        x_hat = torch.sigmoid(self.FC_output(out))\n",
    "        \n",
    "        return x_hat\n",
    "    \n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = self.latent_dim\n",
    "        for i in range(len(cfg)):\n",
    "            if cfg[i] == 'M':\n",
    "                layers += [nn.ConvTranspose2d(cfg[i-1], cfg[i-1], kernel_size=2, stride=2)] # in decoder, we should upsample the image, instead of downsample it\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, cfg[i], kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(cfg[i]),\n",
    "                           nn.GELU()] # changed from ReLU\n",
    "                in_channels = cfg[i]\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "!jupyter nbconvert --to script VAE_CIFAR100_test.ipynb!jupyter nbconvert --to script VAE_CIFAR100_test.ipynb!jupyter nbconvert --to script VAE_CIFAR100_test.ipynb!jupyter nbconvert --to script VAE_CIFAR100_test.ipynb!jupyter nbconvert --to script VAE_CIFAR100_test.ipynb!jupyter nbconvert --to script VAE_CIFAR100_test.ipynb!jupyter nbconvert --to script VAE_CIFAR100_test.ipynb!jupyter nbconvert --to script VAE_CIFAR100_test.ipynb!jupyter nbconvert --to script VAE_CIFAR100_test.ipynb!jupaefasfkjbasvdbsdvbdvsbkjdsvkbjjfjnfsajafsn\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(Model, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "        \n",
    "    def reparameterization(self, mean, var):\n",
    "        epsilon = torch.randn_like(var).to(DEVICE)        # sampling epsilon        \n",
    "        z = mean + var*epsilon                          # reparameterization trick\n",
    "        return z\n",
    "        \n",
    "                \n",
    "    def forward(self, x):\n",
    "        mean, log_var = self.Encoder(x)\n",
    "        z = self.reparameterization(mean, torch.exp(0.5 * log_var)) # takes exponential function (log var -> var)\n",
    "        \n",
    "        # also here, unflatten()\n",
    "        z = z.view(z.size(0), z.size(1), 1, 1)\n",
    "        \n",
    "        x_hat = self.Decoder(z)\n",
    "        \n",
    "        return x_hat, mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_size = testset[0][0].shape[0] #Fixed, dim 0 is the feature channel number\n",
    "latent_dim = 64 # hyperparameter\n",
    "\n",
    "encoder = Encoder('VGG19',  input_dim=data_size,     latent_dim=latent_dim)\n",
    "decoder = Decoder('VGG19',  latent_dim=latent_dim,   output_dim = data_size)\n",
    "\n",
    "model = Model(Encoder=encoder, Decoder=decoder).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning\n",
    "In CIFAR100. First define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr = 1e-3\n",
    "epochs = 5\n",
    "#BCE_loss = nn.BCELoss() # should we use BCE loss here?\n",
    "\n",
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction='sum')\n",
    "    KLD      = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "\n",
    "    return reproduction_loss + KLD\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr= lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of output from the encoder and decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean shape torch.Size([2, 64, 1, 1]), and mean torch.Size([2, 64, 1, 1])\n",
      "Size of latent space torch.Size([2, 64, 1, 1])\n",
      "The size of x_hat torch.Size([2, 3, 32, 32]) and original input x torch.Size([2, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Random sample\n",
    "x = torch.randn(2, 3, 32, 32)\n",
    "\n",
    "# Encoder test\n",
    "mean, var = encoder(x)\n",
    "print(f\"The mean shape {mean.size()}, and mean {mean.size()}\")\n",
    "#mean = mean.view(mean.size(0),latent_dim)\n",
    "#var = var.view(var.size(0),latent_dim)\n",
    "# Decoder\n",
    "epsilon = torch.randn_like(var).to(DEVICE)        # sampling epsilon        \n",
    "z = mean + var*epsilon\n",
    "\n",
    "print(f\"Size of latent space {z.size()}\")\n",
    "# unflatten it\n",
    "#z = z.view(z.size(0), latent_dim, 1, 1)\n",
    "\n",
    "x_hat = decoder(z)\n",
    "print(f\"The size of x_hat {x_hat.size()} and original input x {x.size()}\")\n",
    "#print(f\"the loss from de- and encodering of x is {loss_function(x, x_hat, mean, var)}\")\n",
    "\n",
    "# Model\n",
    "#x_hat, mean, var = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, model, loader, plot : bool = False):\n",
    "    loss_list = []\n",
    "    model.train()\n",
    "        \n",
    "    # Train the model\n",
    "    total_step = len(loader)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for batch_idx, (x, _) in enumerate(loader):\n",
    "        \n",
    "            x = x.to(DEVICE)\n",
    "            \n",
    "            # clear gradients for this training step \n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "            x_hat, mean, log_var = model(x)\n",
    "            loss = loss_function(x, x_hat, mean, log_var)\n",
    "            \n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()\n",
    "            \n",
    "            # apply gradients  \n",
    "            optimizer.step()\n",
    "            \n",
    "                      \n",
    "            \n",
    "            if (batch_idx+1) % 1 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch + 1, epochs, batch_idx + 1, total_step, loss.item()))\n",
    "                if plot:\n",
    "                    loss_list.append(loss.item())\n",
    "                \n",
    "                pass\n",
    "        pass\n",
    "    \n",
    "    if plot:\n",
    "        xVals = list(range(1, len(loss_list) + 1))\n",
    "        \n",
    "        # subplots define number of rows and columns\n",
    "        fig, ax1 = plt.subplots(1, 1)\n",
    "        ax1.plot(xVals, loss_list, 'o-')\n",
    "        fig.suptitle(f\"Loss through training.\")\n",
    "        ax1.set_ylabel(\"Loss over training\")\n",
    "       \n",
    "    print(\"Done!\")            \n",
    "    pass\n",
    "\n",
    "train(epochs, model, trainloader, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-465bb2b3deef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msaveModelPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../trainedModels/VAE_CIFAR100.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveModelPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "saveModelPath = \"../trainedModels/VAE_CIFAR100.pth\"\n",
    "torch.save(model.state_dict(), saveModelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to python file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook VAE_CIFAR100_test.ipynb to script\n",
      "[NbConvertApp] Writing 9332 bytes to VAE_CIFAR100_test.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script VAE_CIFAR100_test.ipynb"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d806fedfadc4f43df997bb69e69664c5753a645548adea2a58a56079e3db770c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
