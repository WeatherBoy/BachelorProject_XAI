{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing some parameter of some attack\n",
    "I wanted to make a test of some attack-parameter, to see how it affects the model (net) that we are attacking. A great example is the increasing epsilon of FGSM that proved too (quite intutivly) lower the accuracy of the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, utils, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import exists\n",
    "%matplotlib inline\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumb function\n",
    "...that I will probably only use a couple of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msg(\n",
    "    message: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        message (str): a message of type string, which will be printed to the terminal\n",
    "            with some decoration.\n",
    "\n",
    "    Description:\n",
    "        This function takes a message and prints it nicely\n",
    "\n",
    "    Output:\n",
    "        This function has no output, it prints directly to the terminal\n",
    "    \"\"\"\n",
    "\n",
    "    # word_list makes sure that the output of msg is more readable\n",
    "    sentence_list = message.split(sep=\"\\n\")\n",
    "    # the max-function can apparently be utilised like this:\n",
    "    longest_sentence = max(sentence_list, key=len)\n",
    "\n",
    "    n = len(longest_sentence)\n",
    "    n2 = n // 2 - 1\n",
    "    print(\">\" * n2 + \"  \" + \"<\" * n2)\n",
    "    print(message)\n",
    "    print(\">\" * n2 + \"  \" + \"<\" * n2 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data\n",
    "\n",
    "Downloading, in this case, those pesky pictures of real world stuff.\n",
    "\n",
    "Here I also split the train set into validation and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "VALIDATION_SPLIT = 0.2\n",
    "RANDOM_SEED = 42\n",
    "NUM_WORKERS = 4\n",
    "LR = 1e-3\n",
    "\n",
    "# Setting seeds ##############################################\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "##############################################################\n",
    "\n",
    "trainval_set = datasets.CIFAR100(\n",
    "    root = '../data/datasetCIFAR100',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True\n",
    "    )\n",
    "\n",
    "test_set = datasets.CIFAR100(\n",
    "    root = '../data/datasetCIFAR100', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    "    )\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "train_num = int(len(trainval_set) * (1 - VALIDATION_SPLIT))\n",
    "train_set, val_set = random_split(trainval_set, [train_num, len(trainval_set) - train_num])\n",
    "msg(\"Split train data into trainset and validation set.\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "classes = trainval_set.classes # or class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediary test\n",
    "Testing whether the pics are in range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_Want_Intermediary_Test = True\n",
    "Nsamples = 100\n",
    "\n",
    "if I_Want_Intermediary_Test:\n",
    "    # Finding max of input images\n",
    "    from math import inf\n",
    "    maxNum = -inf\n",
    "    minNum = inf\n",
    "    for i in range(Nsamples):\n",
    "        sample_idx = torch.randint(len(trainval_set), size=(1,)).item()\n",
    "        img, _ = trainval_set[sample_idx]\n",
    "        tempMax = torch.max(img)\n",
    "        tempMin = torch.min(img)\n",
    "        if maxNum < tempMax:\n",
    "            maxNum = tempMax\n",
    "        if tempMin < minNum:\n",
    "            minNum = tempMin\n",
    "\n",
    "    msg(f\"Smallest in number in these images: {minNum}\\n Greatest number in sample images: {maxNum}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=False).to(device)\n",
    "checkpoint = torch.load(save_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
