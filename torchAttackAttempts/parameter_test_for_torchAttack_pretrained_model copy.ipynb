{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing some parameter of some attack\n",
    "I wanted to make a test of some attack-parameter, to see how it affects the model (net) that we are attacking. A great example is the increasing epsilon of FGSM that proved to (quite intutivly) lower the accuracy of the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import datasets, utils, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os.path import exists\n",
    "%matplotlib inline\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {DEVICE} device\")\n",
    "\n",
    "MODEL_PATH = \"C:/Users/daflo/Documents/DTU/Semester_6/Bachelor/BachelorXAI/BachelorProject_XAI/downloadedJobs/EfficientNet_b7_SecondAttempt_warm_restart_BIG2smallLR_weightDecay_1e6-190c0ba3-ee49-4735-aa48-d41afa8c3c0c/adversarial_efficientnet_b7_cifar100.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumb function\n",
    "...that I will probably only use a couple of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msg(\n",
    "    message: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        message (str): a message of type string, which will be printed to the terminal\n",
    "            with some decoration.\n",
    "\n",
    "    Description:\n",
    "        This function takes a message and prints it nicely\n",
    "\n",
    "    Output:\n",
    "        This function has no output, it prints directly to the terminal\n",
    "    \"\"\"\n",
    "\n",
    "    # word_list makes sure that the output of msg is more readable\n",
    "    sentence_list = message.split(sep=\"\\n\")\n",
    "    # the max-function can apparently be utilised like this:\n",
    "    longest_sentence = max(sentence_list, key=len)\n",
    "\n",
    "    n = len(longest_sentence)\n",
    "    n2 = n // 2 - 1\n",
    "    print(\">\" * n2 + \"  \" + \"<\" * n2)\n",
    "    print(message)\n",
    "    print(\">\" * n2 + \"  \" + \"<\" * n2 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading data\n",
    "\n",
    "Downloading, in this case, those pesky pictures of real world stuff.\n",
    "\n",
    "Here I also split the train set into validation and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>  <<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Split train data into trainset and validation set.\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>  <<<<<<<<<<<<<<<<<<<<<<<<\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "VALIDATION_SPLIT = 0.2\n",
    "RANDOM_SEED = 42\n",
    "NUM_WORKERS = 1\n",
    "\n",
    "# Setting seeds ##############################################\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "##############################################################\n",
    "\n",
    "trainval_set = datasets.CIFAR100(\n",
    "    root = '../data/datasetCIFAR100',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True\n",
    "    )\n",
    "\n",
    "test_set = datasets.CIFAR100(\n",
    "    root = '../data/datasetCIFAR100', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    "    )\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "train_num = int(len(trainval_set) * (1 - VALIDATION_SPLIT))\n",
    "train_set, val_set = random_split(trainval_set, [train_num, len(trainval_set) - train_num])\n",
    "msg(\"Split train data into trainset and validation set.\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "classes = trainval_set.classes # or class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediary test\n",
    "Testing whether the pics are in range [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>>  <<<<<<<<<<<<<<<<<<\n",
      "Smallest in number in these images: 0.0\n",
      " Greatest number in sample images: 1.0\n",
      ">>>>>>>>>>>>>>>>>>  <<<<<<<<<<<<<<<<<<\n",
      "\n"
     ]
    }
   ],
   "source": [
    "I_Want_Intermediary_Test = True\n",
    "Nsamples = 100\n",
    "\n",
    "if I_Want_Intermediary_Test:\n",
    "    # Finding max of input images\n",
    "    from math import inf\n",
    "    maxNum = -inf\n",
    "    minNum = inf\n",
    "    for i in range(Nsamples):\n",
    "        sample_idx = torch.randint(len(trainval_set), size=(1,)).item()\n",
    "        img, _ = trainval_set[sample_idx]\n",
    "        tempMax = torch.max(img)\n",
    "        tempMin = torch.min(img)\n",
    "        if maxNum < tempMax:\n",
    "            maxNum = tempMax\n",
    "        if tempMin < minNum:\n",
    "            minNum = tempMin\n",
    "\n",
    "    msg(f\"Smallest in number in these images: {minNum}\\n Greatest number in sample images: {maxNum}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>  <<<<<\n",
      "Loaded model.\n",
      ">>>>>  <<<<<\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.efficientnet_b7(pretrained=False).to(DEVICE)\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=torch.device(DEVICE))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
    "model.eval()\n",
    "msg(\"Loaded model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FGSM Attack\n",
    "(Fast Gradient Sign Method) Attack.\n",
    "Here we define the function that creates the adversarial example by disturbing the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM attack code\n",
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing function\n",
    "This is a testing function written by the peeps at pyTorch. It seems like it does a lot, I am not entirely sure what everything is though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, epsilon, someSeed):\n",
    "    # Manxi's superior testing function\n",
    "\n",
    "\n",
    "    # Accuracy counter\n",
    "    # correct = 0\n",
    "    adv_examples = []\n",
    "    adv_imgs = []\n",
    "    adv_pred_labels = []\n",
    "    adv_attack_labels = []\n",
    "    pred = []\n",
    "    gt = []\n",
    "    \n",
    "    # Loop over all examples in test set\n",
    "    for data, target in test_loader:\n",
    "\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output = model(data)\n",
    "        _, init_pred_index = output.max(1, keepdim=True) # get the index of the max log-probability\n",
    "    \n",
    "        idx = (init_pred_index.flatten() == target.flatten()) # B, bool \n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = data.grad.data\n",
    "        \n",
    "        # NOTE: I put the indexing after the back propagation, \n",
    "        # so that \"data\" appears on the computation graph \n",
    "        # (which is used for computing the gradient)\n",
    "        \n",
    "        data_grad = data_grad[idx, ...]\n",
    "        if not data_grad.size(0):\n",
    "            continue        \n",
    "        \n",
    "        data = data[idx, ...]\n",
    "        output = output[idx, ...] # N, C\n",
    "        target = target[idx] # N\n",
    "        init_pred_index = init_pred_index[idx, ...]\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data)\n",
    "        # print(f\"second output: {output}\")\n",
    "\n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True) # get the index of the max log-probability\n",
    "        \n",
    "        final_pred_index = final_pred[1]\n",
    "        \n",
    "        adv_ex = perturbed_data.detach()\n",
    "        adv_imgs.append(adv_ex)\n",
    "        adv_pred_labels.append(init_pred_index.detach())\n",
    "        adv_attack_labels.append(final_pred_index.detach())\n",
    "\n",
    "        pred.append(final_pred_index.flatten().detach().cpu().numpy())\n",
    "        gt.append(init_pred_index.flatten().detach().cpu().numpy())\n",
    "        \n",
    "    # Calculate final accuracy for this epsilon\n",
    "    #final_acc = correct/float(len(test_loader)) # This is for computing the accuracy over batches\n",
    "    # We usually compute the accuracy over instances\n",
    "    pred = np.concatenate(pred, axis=0)\n",
    "    gt = np.concatenate(gt, axis=0)\n",
    "    correct = np.sum(pred == gt)\n",
    "    final_acc = correct / len(gt)\n",
    "    \n",
    "    # np.random.seed(0) # if you would like to make the result repeatable, you should fix the random seed    \n",
    "    np.random.seed(someSeed)\n",
    "    print(\"the seed:\", someSeed)\n",
    "    adv_imgs = torch.cat(adv_imgs, dim=0).cpu().numpy()\n",
    "    num_random_imgs = 5\n",
    "    \n",
    "    img_num = adv_imgs.shape[0]\n",
    "    rndm_imgs_ID = np.arange(img_num)\n",
    "    np.random.shuffle(rndm_imgs_ID)\n",
    "    rndm_imgs_ID = rndm_imgs_ID[:num_random_imgs] # now we randomly pick 5 indices\n",
    "        \n",
    "    adv_imgs = adv_imgs[rndm_imgs_ID, ...]\n",
    "    adv_pred_labels = torch.cat(adv_pred_labels, dim=0).cpu().numpy()[rndm_imgs_ID, ...]\n",
    "    adv_attack_labels = torch.cat(adv_attack_labels, dim=0).cpu().numpy()[rndm_imgs_ID, ...]\n",
    "    \n",
    "    adv_examples = [(adv_pred_labels[i, ...][0], adv_attack_labels[i, ...][0], adv_imgs[i, ...]) for i in range(num_random_imgs)]     \n",
    "    \n",
    "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(round(epsilon.item(), 3), correct, len(gt), final_acc))\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally we run the attack\n",
    "This also saves some values, so that we can see how the accuracy falls along with greater epsilon (error) rates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the seed: 199900595\n",
      "Epsilon: 0.0\tTest Accuracy = 3628 / 3628 = 1.0\n",
      "the seed: 199900595\n",
      "Epsilon: 0.06\tTest Accuracy = 45 / 3628 = 0.012403528114663727\n",
      "the seed: 199900595\n",
      "Epsilon: 0.12\tTest Accuracy = 44 / 3628 = 0.012127894156560088\n"
     ]
    }
   ],
   "source": [
    "EPSILONS = torch.linspace(0, 0.3, 6)\n",
    "EPSILON_STEP_SIZE = EPSILONS[1].item()\n",
    "\n",
    "accuracies = []\n",
    "examples = []\n",
    "SEED = np.random.randint(low=0, high=2**30)        \n",
    "        \n",
    "# Run test for each epsilon\n",
    "for eps in EPSILONS:\n",
    "    acc, ex = test(model, DEVICE, test_loader, eps, SEED)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "We make an **accuracy** vs. **epsilon*** plot and see that there is a clear correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy vs. Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(EPSILONS, accuracies, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, torch.max(EPSILONS) + EPSILON_STEP_SIZE, step=EPSILON_STEP_SIZE))\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Adversarial Examples\n",
    "Here we show some of the images that are the results of adversarial attacks, alongside the prediction by the network :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot several examples of adversarial samples at each epsilon\n",
    "\n",
    "cnt = 0\n",
    "plt.figure(figsize=(8,10))\n",
    "for i in range(len(EPSILONS)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "        plt.subplot(len(EPSILONS),len(examples[0]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(\"Eps: {}\".format(round(EPSILONS[i].item(), 3)), fontsize=14)\n",
    "        orig,adv,ex = examples[i][j]\n",
    "        \n",
    "        # CIFAR is complicated so we need to reshape and normalize..\n",
    "        reshaped_ex = np.transpose(ex, (1, 2, 0))\n",
    "        #print(f\"min: {min(reshaped_ex.flatten())}\")\n",
    "        #normalised_ex = reshaped_ex / 2     # unnormalize\n",
    "        #print(f\"max: {max(reshaped_ex.flatten())}\")\n",
    "        \n",
    "        plt.title(\"{} -> {}\".format(classes[orig], classes[adv]))\n",
    "        plt.imshow(reshaped_ex)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05908db61d562b6b82dbdd69656403b30dae77f547a66d972e99027ce19f097c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Bachelor_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
